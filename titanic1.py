# -*- coding: utf-8 -*-
"""titanic1.ipynb

Automatically generated by Colaboratory.
"
Original file is located at
    https://colab.research.google.com/drive/1FlnApq_DK9b3f-nqit2S6CrCwJ4HDr0J
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import io
import requests
import matplotlib.pyplot as plt
import seaborn as sns
import math
# %matplotlib inline

github_link = "https://github.com/baskarsundarrajan/Data_Science/blob/baskarsundarrajan-patch-1/titanic1.py"

dataset= pd.read_csv(github_link)
dataset.head()

sns.countplot(x="Survived",data=dataset)#countplot to get the count/frquency,x="fieldname",y=count

sns.countplot(x="Survived",hue="Sex",data=dataset)

sns.countplot(x="Survived",hue="Pclass",data=dataset)

dataset["Age"].plot.hist();#to plot histogram

dataset["Fare"].plot.hist(bins=20,figsize=(10,5))

dataset.info();

sns.countplot(x="SibSp",data=dataset)

dataset.isnull()#check null values in data,true means contains null

dataset.isnull().sum()#check total no. of null values

sns.heatmap(dataset.isnull(),yticklabels=False,cmap='viridis')
#plot nullvalues,now through the map we can see that
#cabin has many null values so we can drop that coloumn
#dataset.isnull() data is passed to heatmap
#yticklable is false when you dont want to label the y axis
#cmap:color coding

sns.boxplot(x="Pclass",y="Age",data=dataset)

dataset.head(5)

dataset.drop("Cabin",axis=1,inplace=True)#drop col Cabin

dataset.head(5)

dataset.dropna(inplace=True)#drop wherever null

dataset.head(5)

sns.heatmap(dataset.isnull(),yticklabels=False,cbar=False)

dataset.isnull().sum()#check total no. of null values

dataset.head(2)#here we can se sex,name,pclass has string data

sex=pd.get_dummies(dataset['Sex'])#convert sex which has string data to categorial data

sex.head(5)

sex=pd.get_dummies(dataset['Sex'],drop_first=True)#drop the first col

sex.head(5)

embarked=pd.get_dummies(dataset['Embarked'])#convert Embarked which has string data to categorial data

embarked.head(5)

embarked=pd.get_dummies(dataset['Embarked'],drop_first=True)#drop the first col

embarked.head(5)

pcl=pd.get_dummies(dataset['Pclass'])#convert Pclass which has string data to categorial data

pcl.head(5)

pcl=pd.get_dummies(dataset['Pclass'],drop_first=True)#drop the first col

pcl.head(5)

dataset=pd.concat([dataset,sex,embarked,pcl],axis=1)#add the coloumns in the original dataset

dataset.head(5)

dataset.drop(['Sex','Embarked','PassengerId','Name','Ticket','Pclass'],axis=1,inplace=True)

dataset.head(5)

x=dataset.drop("Survived",axis=1)

x.head(5)

y=dataset["Survived"]

y.head(5)

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=1,test_size=0.3)

from sklearn.preprocessing import StandardScaler
sc=StandardScaler()

x_train = sc.fit_transform(x_train) #normalising the data
x_test=sc.transform(x_test)

from sklearn.linear_model import LogisticRegression
classifier=LogisticRegression(random_state=0)

classifier.fit(x_train,y_train)
y_pred=classifier.predict(x_test)

from sklearn.metrics import accuracy_score
accuracy_score(y_test,y_pred)*100

from sklearn.metrics import classification_report
classification_report(y_test,y_pred)

from sklearn.metrics import confusion_matrix
confusion_matrix(y_test,y_pred)

